{
 "metadata": {
  "language": "lua",
  "name": "",
  "signature": "sha256:9836c1bcab54eec3625bc38d5624cf09bfb53497427101042b36170a1ae59ebb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "require \"torch\"\n",
      "local nn = require \"nn\"\n",
      "require \"optim\"\n",
      "require \"midiToBinaryVector\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "require \"nn\"\n",
      "local RluMax = torch.class('nn.RluMax', 'nn.Module')\n",
      "\n",
      "function RluMax:__init()\n",
      "    self.mask = torch.Tensor()\n",
      "    self.output = torch.Tensor()\n",
      "    self.gradInput = torch.Tensor()\n",
      "end\n",
      "\n",
      "-- Allow only positive values.\n",
      "function RluMax:updateOutput(input)\n",
      "    local mask = self.mask:resizeAs(input)\n",
      "    local output = self.output:resizeAs(input)\n",
      "\n",
      "    output:cmul(input, torch.gt(mask, input, 0))\n",
      "\n",
      "    return output\n",
      "end\n",
      "\n",
      "-- Gradient is constant for positive values and zero otherwise.\n",
      "function RluMax:updateGradInput(input, gradOutput)\n",
      "    local mask = self.mask:resizeAs(input)\n",
      "    local gradInput = self.gradInput:resizeAs(input)\n",
      "\n",
      "    -- Use subgradient 1 at value 0.\n",
      "    gradInput:cmul(torch.ge(mask, input, 0), gradOutput)\n",
      "\n",
      "    return gradInput\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local torch = require 'torch'\n",
      "local midi = require 'MIDI'\n",
      "mtbv = require \"midiToBinaryVector\"\n",
      "require 'lfs'\n",
      "\n",
      "obj = \n",
      "{\n",
      "    Genre = \"Classical\",\n",
      "    Songs = {}\n",
      "}\n",
      "\n",
      "counter = 0.\n",
      "for filename in lfs.dir(\"./music/classical\") \n",
      "    do --print (\"./music/classical/\"..filename) \n",
      "    if string.find(filename, \".mid\")\n",
      "    then obj.Songs[filename] = midiToBinaryVec(\"./music/classical/\"..filename)\n",
      "    --print(obj.Songs[filename])\n",
      "    end\n",
      "end\n",
      "\n",
      "obj2 = \n",
      "{\n",
      "    Genre = \"Jazz\",\n",
      "    Songs = {}\n",
      "}\n",
      "\n",
      "counter = 0.\n",
      "for filename in lfs.dir(\"./music/jazz\") \n",
      "    do --print (\"./music/classical/\"..filename) \n",
      "    if string.find(filename, \".mid\")\n",
      "    then obj2.Songs[filename] = midiToBinaryVec(\"./music/jazz/\"..filename)\n",
      "    --print(obj.Songs[filename])\n",
      "    end\n",
      "end\n",
      "\n",
      "trainData = {}\n",
      "labels = {}\n",
      "--print(obj.Songs)\n",
      "count = 1\n",
      "for k,v in pairs(obj.Songs)\n",
      "do\n",
      "    labels[count] = 1\n",
      "    trainData[count] = v:t()\n",
      "    count = count + 1\n",
      "    end\n",
      "for k,v in pairs(obj2.Songs)\n",
      "do\n",
      "    --print(k)\n",
      "    labels[count] = 2\n",
      "    trainData[count] = v:t()\n",
      "    count = count + 1\n",
      "    end\n",
      "print(#trainData)\n",
      "--print (table.getn(obj.Songs))\n",
      "--print(labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "503\t\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inp=128;  -- dimensionality of one sequence element \n",
      "outp=50; -- number of derived features for one sequence element\n",
      "kw=1;   -- kernel only operates on one sequence element at once\n",
      "dw=1;   -- we step once and go on to the next sequence element\n",
      " \n",
      "--print(nn)\n",
      "mlp=nn.Sequential()\n",
      "mlp:add(nn.TemporalConvolution(inp,outp,kw,dw))\n",
      "mlp:add(nn.Tanh())\n",
      "mlp:add(nn.Linear(50,25))\n",
      "mlp:add(nn.RluMax())\n",
      "mlp:add(nn.Linear(25,2))\n",
      "--mlp:add(nn.parallel)\n",
      "mlp:add(nn.Mean(1))\n",
      "--mlp:add(nn.Mean(2))\n",
      "mlp2 = nn.TemporalSubSampling (inp,kw,dw)\n",
      "x=torch.rand(8,inp) -- a sequence of 7 elements\n",
      "y=torch.rand(8,1)\n",
      "--print(y)\n",
      "--print(x)\n",
      "--print(mlp2:forward(x))\n",
      "print(mlp:forward(x))\n",
      "model = mlp\n",
      "--print(x)\n",
      "--print (trainData)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0.01 *\n",
        "-2.3212\n",
        " 2.3828\n",
        "[torch.FloatTensor of dimension 2]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlp = nn.Sequential()\n",
      "mlp:add( nn.Linear(10, 25) ) -- 10 input, 25 hidden units\n",
      "mlp:add( nn.Tanh() ) -- some hyperbolic tangent transfer function\n",
      "mlp:add( nn.Linear(25, 1) ) -- 1 output\n",
      "\n",
      "print(mlp:forward(torch.randn(10,10)))\n",
      "print(model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "-0.2803\n",
        "-0.2974\n",
        "-0.0940\n",
        "-0.5829\n",
        "-0.0551\n",
        "-0.2551\n",
        "-0.4000\n",
        " 0.1748\n",
        "-0.2233\n",
        " 0.0925\n",
        "[torch.FloatTensor of dimension 10x1]\n",
        "\n",
        "nn.Sequential {\n",
        "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> output]\n",
        "  (1): nn.TemporalConvolution\n",
        "  (2): nn.Tanh\n",
        "  (3): nn.Linear(50 -> 25)\n",
        "  (4): nn.RluMax\n",
        "  (5): nn.Linear(25 -> 2)\n",
        "  (6): nn.Mean\n",
        "}\n",
        "{\n",
        "  output : FloatTensor - size: 2\n",
        "  gradInput : FloatTensor - empty\n",
        "  modules : \n",
        "    {\n",
        "      1 : \n",
        "        nn.TemporalConvolution\n",
        "        {\n",
        "          bias : FloatTensor - size: 50\n",
        "          weight : FloatTensor - size: 50x128\n",
        "          gradInput : FloatTensor - empty\n",
        "          gradBias : FloatTensor - size: 50\n",
        "          dW : 1\n",
        "          gradWeight : FloatTensor - size: 50x128\n",
        "          output : FloatTensor - size: 8x50\n",
        "          outputFrameSize : 50\n",
        "          inputFrameSize : 128\n",
        "          kW : 1\n",
        "        }\n",
        "    "
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "  2 : \n",
        "        nn.Tanh\n",
        "        {\n",
        "          gradInput : FloatTensor - empty\n",
        "          output : FloatTensor - size: 8x50\n",
        "        }\n",
        "      3 : \n",
        "        nn.Linear(50 -> 25)\n",
        "        {\n",
        "          bias : FloatTensor - size: 25\n",
        "          weight : FloatTensor - size: 25x50\n",
        "          gradInput : FloatTensor - empty\n",
        "          gradBias : FloatTensor - size: 25\n",
        "          gradWeight : FloatTensor - size: 25x50\n",
        "          output : FloatTensor - size: 8x25\n",
        "          addBuffer : FloatTensor - size: 8\n",
        "        }\n",
        "      4 : \n",
        "        nn.RluMax\n",
        "        {\n",
        "          mask : FloatTensor - size: 8x25\n",
        "          output : FloatTensor - size: 8x25\n",
        "          gradInput : FloatTensor - empty\n",
        "        }\n",
        "      5 : \n",
        "        nn.Linear(25 -> 2)\n",
        "        {\n",
        "          bias : FloatTensor - size: 2\n",
        "          weight : FloatTensor - size: 2x25\n",
        "          gradInput : FloatTensor - empty\n",
        "          gradBias : FloatTensor - size: 2\n",
        "          gradWeight : FloatTensor - size: 2x25\n",
        "          output : FloatTensor - size: 8x2\n",
        "          addBuffer : FloatTensor - size: 8\n",
        "        }\n",
        "      6 : \n",
        "        nn.Mean\n",
        "        {\n",
        "          output : FloatTensor - size: 2\n",
        "          gradInput : FloatTensor - empty\n",
        "          dimension : 1\n",
        "        "
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "}\n",
        "    }\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "criterion = nn.ClassNLLCriterion()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- classes\n",
      "classes = {'Classical','Jazz'}\n",
      "\n",
      "-- This matrix records the current confusion across classes\n",
      "confusion = optim.ConfusionMatrix(classes)\n",
      "\n",
      "-- Log results to files\n",
      "trainLogger = optim.Logger(paths.concat('.', 'train.log'))\n",
      "testLogger = optim.Logger(paths.concat('.', 'test.log'))\n",
      "\n",
      "-- Retrieve parameters and gradients:\n",
      "-- this extracts and flattens all the trainable parameters of the mode\n",
      "-- into a 1-dim vector\n",
      "if model then\n",
      "   parameters,gradParameters = model:getParameters()\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "optimState = {\n",
      "    learningRate = 0.1,\n",
      "    weightDecay = 0.1,\n",
      "    momentum = 0.01,\n",
      "    learningRateDecay = 1e-7\n",
      "}\n",
      "optimMethod = optim.sgd\n",
      "print(torch.randperm(11))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "  7\n",
        "  9\n",
        "  1\n",
        " 11\n",
        "  3\n",
        "  6\n",
        "  4\n",
        "  5\n",
        "  8\n",
        "  2\n",
        " 10\n",
        "[torch.FloatTensor of dimension 11]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epoch = 1\n",
      "function train()\n",
      "\n",
      "   -- epoch tracker\n",
      "   epoch = epoch or 1\n",
      "\n",
      "   -- local vars\n",
      "   local time = sys.clock()\n",
      "\n",
      "   -- set model to training mode (for modules that differ in training and testing, like Dropout)\n",
      "   model:training()\n",
      "   --print(#trainData)\n",
      "   -- shuffle at each epoch\n",
      "   shuffle = torch.randperm(#trainData)\n",
      "   print(shuffle:size(1) - #trainData)\n",
      "   -- do one epoch\n",
      "   print('==> doing epoch on training data:')\n",
      "   print(\"==> online epoch # \" .. epoch .. ' [batchSize = ' .. 64 .. ']')\n",
      "    print(#trainData)\n",
      "    \n",
      "   for t = 1,#trainData do\n",
      "        --break\n",
      "      --print (\"HERE\" .. shuffle[t])\n",
      "      -- disp progress\n",
      "      xlua.progress(t, #trainData)\n",
      "      --for ts = 1,trainData[shuffle[t]]:size(2),64 do\n",
      "      -- create mini batch\n",
      "      local inputs = {}\n",
      "      inputs[1] = trainData[shuffle[t]]\n",
      "      --print(inputs[0]:size(2))\n",
      "      local targets = {}\n",
      "        targets[1] = labels[shuffle[t]]\n",
      "      --for i = ts,math.min(ts+63,trainData[shuffle[t]]:size(2)) do\n",
      "      --   -- load new sample\n",
      "         --local input = trainData[shuffle[t]][i]\n",
      "         --local target = labels[shuffle[t]][i]\n",
      "         --input = input:double()\n",
      "         --table.insert(inputs, input)\n",
      "         --print(input)\n",
      "         --table.insert(targets, target)\n",
      "      --end\n",
      "\n",
      "      --print(inputs)\n",
      "     -- print(targets)\n",
      "\n",
      "      -- create closure to evaluate f(X) and df/dX\n",
      "      local feval = function(x)\n",
      "                       -- get new parameters\n",
      "                       if x ~= parameters then\n",
      "                          parameters:copy(x)\n",
      "                       end\n",
      "\n",
      "                       -- reset gradients\n",
      "                       gradParameters:zero()\n",
      "\n",
      "                       -- f is the average of all criterions\n",
      "                       local f = 0\n",
      "\n",
      "                       -- evaluate function for complete mini batch\n",
      "                       for i = 1,#inputs do\n",
      "                          print(\"BEFORE FORWARD\")\n",
      "                        print(i)\n",
      "                          --print(inputs[i])\n",
      "                          -- estimate f\n",
      "                          local output = model:forward(inputs[i])\n",
      "                          print (\"AFTER FORWARD\")\n",
      "                          print (\"NEO\")\n",
      "                          print(output)\n",
      "                          print(targets[i])\n",
      "                          local err = criterion:forward(output, targets[i])\n",
      "                          print(\"BLAH\")\n",
      "                          f = f + err\n",
      "\n",
      "                          -- estimate df/dW\n",
      "                          local df_do = criterion:backward(output, targets[i])\n",
      "                          model:backward(inputs[i], df_do)\n",
      "\n",
      "                          -- update confusion\n",
      "                          confusion:add(output, targets[i])\n",
      "                       end\n",
      "\n",
      "                       -- normalize gradients and f(X)\n",
      "                       gradParameters:div(#inputs)\n",
      "                       f = f/#inputs\n",
      "\n",
      "                       -- return f and df/dX\n",
      "                       return f,gradParameters\n",
      "                    end\n",
      "\n",
      "      -- optimize on current mini-batch\n",
      "      if optimMethod == optim.asgd then\n",
      "            print \"HERE OPTIM2\"\n",
      "         _,_,average = optimMethod(feval, parameters, optimState)\n",
      "      else\n",
      "        print \"HERE OPTIM\"\n",
      "         optimMethod(feval, parameters, optimState)\n",
      "      end\n",
      "  -- end\n",
      "   end\n",
      "\n",
      "   -- time taken\n",
      "   time = sys.clock() - time\n",
      "   time = time / #trainData\n",
      "   print(\"\\n==> time to learn 1 sample = \" .. (time*1000) .. 'ms')\n",
      "\n",
      "   -- print confusion matrix\n",
      "   print(confusion)\n",
      "\n",
      "   -- update logger/plot\n",
      "   trainLogger:add{['% mean class accuracy (train set)'] = confusion.totalValid * 100}\n",
      "   if true then\n",
      "      trainLogger:style{['% mean class accuracy (train set)'] = '-'}\n",
      "      trainLogger:plot()\n",
      "   end\n",
      "\n",
      "   -- save/log current net\n",
      "   local filename = paths.concat('.', 'model.net')\n",
      "   os.execute('mkdir -p ' .. sys.dirname(filename))\n",
      "   print('==> saving model to '..filename)\n",
      "   torch.save(filename, model)\n",
      "\n",
      "   -- next epoch\n",
      "   confusion:zero()\n",
      "   epoch = epoch + 1\n",
      "end\n",
      "train()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "[string \"epoch = 1...\"]:106: '=' expected near 'confusion'",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "[string \"epoch = 1...\"]:106: '=' expected near 'confusion'"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function test()\n",
      "   -- local vars\n",
      "   local time = sys.clock()\n",
      "\n",
      "   -- averaged param use?\n",
      "   if average then\n",
      "      cachedparams = parameters:clone()\n",
      "      parameters:copy(average)\n",
      "   end\n",
      "\n",
      "   -- set model to evaluate mode (for modules that differ in training and testing, like Dropout)\n",
      "   model:evaluate()\n",
      "\n",
      "   -- test over test data\n",
      "   print('==> testing on test set:')\n",
      "   for t = 1,testData:size() do\n",
      "      -- disp progress\n",
      "      xlua.progress(t, testData:size())\n",
      "\n",
      "      -- get new sample\n",
      "      local input = testData.data[t]\n",
      "      input = input:double()\n",
      "      local target = testData.labels[t]\n",
      "\n",
      "      -- test sample\n",
      "      local pred = model:forward(input)\n",
      "      confusion:add(pred, target)\n",
      "   end\n",
      "\n",
      "   -- timing\n",
      "   time = sys.clock() - time\n",
      "   time = time / testData:size()\n",
      "   print(\"\\n==> time to test 1 sample = \" .. (time*1000) .. 'ms')\n",
      "\n",
      "   -- print confusion matrix\n",
      "   print(confusion)\n",
      "\n",
      "   -- update log/plot\n",
      "   testLogger:add{['% mean class accuracy (test set)'] = confusion.totalValid * 100}\n",
      "   if true then\n",
      "      testLogger:style{['% mean class accuracy (test set)'] = '-'}\n",
      "      testLogger:plot()\n",
      "   end\n",
      "\n",
      "   -- averaged param use?\n",
      "   if average then\n",
      "      -- restore parameters\n",
      "      parameters:copy(cachedparams)\n",
      "   end\n",
      "   \n",
      "   -- next iteration:\n",
      "   confusion:zero()\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i=1,20 do\n",
      "    train()\n",
      "    --test()\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "[string \"for i=1,20 do...\"]:2: attempt to call global 'train' (a nil value)\nstack traceback:\n\t[string \"for i=1,20 do...\"]:2: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/zayik/torch/install/share/lua/5.1/itorch/main.lua:174: in function </home/zayik/torch/install/share/lua/5.1/itorch/main.lua:140>\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/zayik/torch/install/share/lua/5.1/itorch/main.lua:341: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406170",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "[string \"for i=1,20 do...\"]:2: attempt to call global 'train' (a nil value)\nstack traceback:\n\t[string \"for i=1,20 do...\"]:2: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/zayik/torch/install/share/lua/5.1/itorch/main.lua:174: in function </home/zayik/torch/install/share/lua/5.1/itorch/main.lua:140>\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/zayik/torch/install/share/lua/5.1/itorch/main.lua:341: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406170"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 180,
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}