{
 "metadata": {
  "language": "lua",
  "name": "",
  "signature": "sha256:7efcb85d9f928d67d0229bbb9d37c2a45502c69d816641d442f2725509e60d34"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local torch = require 'torch'\n",
      "local nn = require \"nn\"\n",
      "local midi = require 'MIDI'\n",
      "require \"nn\"\n",
      "require \"optim\"\n",
      "require \"midiToBinaryVector\"\n",
      "require 'DatasetGenerator'\n",
      "require 'lfs'\n",
      "require 'math'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "--Step 1: Gather our training and testing data - trainData and testData contain a table of Songs and Labels\n",
      "trainData = {}\n",
      "testData = {}\n",
      "classes = {}\n",
      "trainData, testData, classes = GetTrainAndTestData(\"./music\", .5)\n",
      "--print(classes)\n",
      "--print(trainData.Labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Gathering Midi Data\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Finished gathering Midi Data\t\n",
        "Splitting Midi Data\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Finished Splitting Midi Data\t\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "--print(trainData.Labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "--Step 2: Create the model\n",
      "inp = 128;  -- dimensionality of one sequence element \n",
      "outp = 32; -- number of derived features for one sequence element\n",
      "kw = 128;   -- kernel only operates on one sequence element at once\n",
      "dw = 128;   -- we step once and go on to the next sequence element\n",
      "spl = 128 -- split constant\n",
      "mlp=nn.Sequential()\n",
      "mlp:add(nn.TemporalConvolution(inp,128,kw,dw))\n",
      "mlp:add(nn.Sigmoid())\n",
      "mlp:add(nn.Linear(128,1))\n",
      "mlp:add(nn.Sum(1))\n",
      "mlp:add(nn.LogSoftMax())\n",
      "model = mlp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "--Step 3: Defne Our Loss Function\n",
      "criterion = nn.BCECriterion()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- classes\n",
      "--classes = {'Classical','Jazz'}\n",
      "--Obtained from GetTrainAndTestData\n",
      "\n",
      "-- This matrix records the current confusion across classes\n",
      "confusion = optim.ConfusionMatrix(1)\n",
      "print(confusion)\n",
      "-- Log results to files\n",
      "trainLogger = optim.Logger(paths.concat('.', 'train.log'))\n",
      "testLogger = optim.Logger(paths.concat('.', 'test.log'))\n",
      "\n",
      "-- Retrieve parameters and gradients:\n",
      "-- this extracts and flattens all the trainable parameters of the mode\n",
      "-- into a 1-dim vector\n",
      "if model then\n",
      "   parameters,gradParameters = model:getParameters()\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "ConfusionMatrix:\n",
        "[[       0]]  nan% \n",
        " + average row correct: nan% \n",
        " + average rowUcol correct (VOC measure): nan% \n",
        " + global correct: nan%\n",
        "{\n",
        "  averageUnionValid : nan\n",
        "  _targ_idx : LongTensor - empty\n",
        "  valids : FloatTensor - size: 1\n",
        "  classes : table: 0x40ded508\n",
        "  _target : FloatTensor - empty\n",
        "  mat : FloatTensor - size: 1x1\n",
        "  _pred_idx : LongTensor - empty\n",
        "  _max : FloatTensor - empty\n",
        "  unionvalids : FloatTensor - size: 1\n",
        "  nclasses : 1\n",
        "  totalValid : nan\n",
        "  _prediction : FloatTensor - empty\n",
        "  averageValid : nan\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "optimState = {\n",
      "    learningRate = 0.001,\n",
      "    weightDecay = 0.01,\n",
      "    momentum = 0.0000,\n",
      "    learningRateDecay = 5e-7\n",
      "}\n",
      "optimMethod = optim.sgd\n",
      "--print(torch.randperm(11))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epoch = 1\n",
      "function train()\n",
      "\n",
      "   -- epoch tracker\n",
      "   epoch = epoch or 1\n",
      "\n",
      "   -- local vars\n",
      "   local time = sys.clock()\n",
      "\n",
      "   -- set model to training mode (for modules that differ in training and testing, like Dropout)\n",
      "   model:training()\n",
      "   --print(#trainData)\n",
      "   -- shuffle at each epoch\n",
      "   shuffle = torch.randperm(trainData:size())\n",
      "\n",
      "    \n",
      "\n",
      "   for t = 1, trainData:size() do\n",
      "   \n",
      "      local inputs = {}\n",
      "      --inputs[1] = trainData.Songs[shuffle[t]]\n",
      "      --print(inputs[0]:size(2))\n",
      "      local targets = {}\n",
      "      --targets[1] = trainData.Labels[shuffle[t]]\n",
      "       table.insert(inputs, trainData.Songs[shuffle[t]])\n",
      "       table.insert(targets, trainData.Labels[shuffle[t]][1])      \n",
      "\t\n",
      "\t\n",
      "\t\n",
      "    --print(inputs)\n",
      "    -- print(targets)\n",
      "\n",
      "      -- create closure to evaluate f(X) and df/dX\n",
      "      local feval = function(x)\n",
      "                   -- get new parameters\n",
      "\t               if x ~= parameters then\n",
      "\t                  parameters:copy(x)\n",
      "\t               end\n",
      "\t               -- reset gradients\n",
      "\t               gradParameters:zero()\n",
      "\n",
      "\t               -- f is the average of all criterions\n",
      "\t               local f = 0\n",
      "\t               local spl_counter = 0\n",
      "\t               --print(\"Evaluating mini-batch\")\n",
      "\t               -- evaluate function for complete mini batch\n",
      "\t               for i = 1,#inputs do\n",
      "\t             \n",
      "\t                  spl_counter  = spl_counter+1\n",
      "\n",
      "\t               local output = model:forward(inputs[i])\n",
      "                      --output = output / output:norm()                          \n",
      "                    --print(\"Output:\")\n",
      "                    --print(output)\n",
      "                    if targets[i] == 0 then targets[i] = 2 end\n",
      "                    --print(targets[i])\n",
      "                \n",
      "                  temp = torch.Tensor(1,0)\n",
      "                  temp[1] = targets[i]\n",
      "                  targets[i] = temp\n",
      "                  --print(\"Target\")\n",
      "                  --print(targets[i])\n",
      "\t\t          local err = criterion:forward(output, targets[i])\n",
      "\t               f = f + err        \n",
      "                current_loss = current_loss + f\n",
      "                  --print(\"Calculated Error\")\n",
      "\n",
      "\t               local df_do = criterion:backward(output, targets[i])\n",
      "                \n",
      "                  --print(\"Calculated fd_do\")\n",
      "                    --print(\"Determined df_do\")\n",
      "\t                  model:backward(inputs[i], df_do)\n",
      "                      --print(\"Applied model:backward\")\n",
      "\t                  confusion:add(output, targets[i])\n",
      "                    --print(\"Updated Conf Matrix\")\n",
      "\n",
      "\t               --end\n",
      "\t               end\n",
      "\n",
      "\t               -- normalize gradients and f(X)\n",
      "\t               gradParameters:div(spl_counter)\n",
      "\t               f = f/spl_counter\n",
      "                    current_loss = current_loss/ spl_counter\n",
      "                 --print(f)\n",
      "\t               --print(\"Returning from feval\")\n",
      "\t               -- return f and df/dX\n",
      "                    --print(\"Before grad param\")\n",
      "\n",
      "                    \n",
      "                    --print(\"After grad param\")\n",
      "\t               return f,gradParameters\n",
      "\t            end\n",
      "\n",
      "\t           \n",
      "\t--print(\"Before optim.sgd\")\n",
      "\toptim.sgd(feval, parameters, optimState)\n",
      "    --current_loss = current_loss + fs\n",
      "\t--print(\"After optim.sgd\")\n",
      "    \n",
      "   end\n",
      "    current_loss = current_loss / trainData:size()\n",
      "    --print(\"Before taking time\")\n",
      "    print(current_loss)\n",
      "   -- time taken\n",
      "   time = sys.clock() - time\n",
      "   time = time / #trainData\n",
      "   --print(\"\\n==> time to learn 1 sample = \" .. (time*1000) .. 'ms')\n",
      "\n",
      "   -- print confusion matrix\n",
      "   print(confusion)\n",
      "\n",
      "   -- update logger/plot\n",
      "   trainLogger:add{['% mean class accuracy (train set)'] = confusion.totalValid * 100}\n",
      "   if true then\n",
      "      trainLogger:style{['% mean class accuracy (train set)'] = '-'}\n",
      "      trainLogger:plot()\n",
      "   end\n",
      "\n",
      "   -- save/log current net\n",
      "   local filename = paths.concat('.', 'model.net')\n",
      "   os.execute('mkdir -p ' .. sys.dirname(filename))\n",
      "   print('==> saving model to '..filename)\n",
      "   torch.save(filename, model)\n",
      "\n",
      "   -- next epoch\n",
      "   confusion:zero()\n",
      "   epoch = epoch + 1\n",
      "end\n",
      "current_loss = 0\n",
      "train()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "-20.442800868902\t\n",
        "ConfusionMatrix:\n",
        "[[     665]]  100.000% \n",
        " + average row correct: 100% \n",
        " + average rowUcol correct (VOC measure): 100% \n",
        " + global correct: 100%\n",
        "{\n",
        "  averageUnionValid : 1\n",
        "  _targ_idx : LongTensor - size: 1\n",
        "  valids : FloatTensor - size: 1\n",
        "  classes : table: 0x411dce98\n",
        "  _target : FloatTensor - size: 1\n",
        "  mat : FloatTensor - size: 1x1\n",
        "  _pred_idx : LongTensor - size: 1\n",
        "  _max : FloatTensor - size: 1\n",
        "  unionvalids : FloatTensor - size: 1\n",
        "  nclasses : 1\n",
        "  totalValid : 1\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "  _prediction : FloatTensor - size: 1\n",
        "  averageValid : 1\n",
        "}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "==> saving model to /home/zayik/Desktop/CS491/RNNMC_BAG/model.net\t\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset={};\n",
      "function dataset:size() return #(dataset) end -- 100 examples\n",
      "\n",
      "for i=1,trainData:size() do \n",
      "  local input = trainData.Songs[i]   -- normally distributed example in 2d\n",
      "  local output = torch.Tensor(1);\n",
      "  temp = torch.Tensor(1,0)\n",
      "  temp[1] = trainData.Labels[i][1]\n",
      "  output = temp \n",
      "  dataset[i] = {input, output}\n",
      "end\n",
      "\n",
      "print(dataset:size())\n",
      "criterion = nn.BCECriterion()  \n",
      "trainer = nn.StochasticGradient(mlp, criterion)\n",
      "trainer.learningRate = 0.001\n",
      "trainer.momentum = 0.0\n",
      "trainer.maxIteration = 2\n",
      "trainer:train(dataset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "665\t\n",
        "# StochasticGradient: training\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "# current error = nan\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "# current error = nan\t\n",
        "# StochasticGradient: you have reached the maximum number of iterations\t\n",
        "# training error = nan\t\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function test()\n",
      "   -- local vars\n",
      "   local time = sys.clock()\n",
      "\n",
      "   -- averaged param use?\n",
      "   if average then\n",
      "      cachedparams = parameters:clone()\n",
      "      parameters:copy(average)\n",
      "   end\n",
      "\n",
      "   -- set model to evaluate mode (for modules that differ in training and testing, like Dropout)\n",
      "   model:evaluate()\n",
      "  print(testData:size())\n",
      "   -- test over test data\n",
      "   print('==> testing on test set:')\n",
      "   for t = 1,testData:size() do\n",
      "      -- disp progress\n",
      "      xlua.progress(t, testData:size())\n",
      "\n",
      "      -- get new sample\n",
      "      local input = testData.Songs[t]\n",
      "      --input = input:double()\n",
      "      local target = testData.Labels[t][1]\n",
      "      --if target == 0 then target = 2 end\n",
      "        \n",
      "      local pred = model:forward(input)\n",
      "      --pred = torch.reshape(pred, 2)\n",
      "\n",
      "      confusion:add(pred, target)\n",
      "      end\n",
      "      \n",
      "   time = sys.clock() - time\n",
      "   time = time / testData:size()\n",
      "   print(\"\\n==> time to test 1 sample = \" .. (time*1000) .. 'ms')\n",
      "\n",
      "   -- print confusion matrix\n",
      "   print(confusion)\n",
      "\n",
      "   -- update log/plot\n",
      "   testLogger:add{['% mean class accuracy (test set)'] = confusion.totalValid * 100}\n",
      "   if true then\n",
      "      testLogger:style{['% mean class accuracy (test set)'] = '-'}\n",
      "      testLogger:plot()\n",
      "   end\n",
      "\n",
      "   -- averaged param use?\n",
      "   if average then\n",
      "      -- restore parameters\n",
      "      parameters:copy(cachedparams)\n",
      "   end\n",
      "   \n",
      "   -- next iteration:\n",
      "   confusion:zero()\n",
      "end\n",
      "test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "667\t\n",
        "==> testing on test set:\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "Progress: 173 / 667\t\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i = 1, 2 do\n",
      "    train()\n",
      "    --test()\n",
      "end\n",
      "test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "Finished Splitting Midi Data\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "nan\t\n",
        "ConfusionMatrix:\n",
        "[[     665]]  100.000% \n",
        " + average row correct: 100% \n",
        " + average rowUcol correct (VOC measure): 100% \n",
        " + global correct: 100%\n",
        "{\n",
        "  averageUnionValid : 1\n",
        "  _targ_idx : LongTensor - size: 1\n",
        "  valids : FloatTensor - size: 1\n",
        "  classes : table: 0x4080e8d0\n",
        "  _target : FloatTensor - size: 1\n",
        "  mat : FloatTensor - size: 1x1\n",
        "  _pred_idx : LongTensor - size: 1\n",
        "  _max : FloatTensor - size: 1\n",
        "  unionvalids : FloatTensor - size: 1\n",
        "  nclasses : 1\n",
        "  totalValid : 1\n",
        "  _prediction : FloatTensor - size: 1\n",
        "  averageValid : 1\n",
        "}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "==> saving model to /home/zayik/Desktop/CS491/RNNMC_BAG/model.net\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "nan\t\n",
        "ConfusionMatrix:\n",
        "[[     665]]  100.000% \n",
        " + average row correct: 100% \n",
        " + average rowUcol correct (VOC measure): 100% \n",
        " + global correct: 100%\n",
        "{\n",
        "  averageUnionValid : 1\n",
        "  _targ_idx : LongTensor - size: 1\n",
        "  valids : FloatTensor - size: 1\n",
        "  classes : table: 0x4080e8d0\n",
        "  _target : FloatTensor - size: 1\n",
        "  mat : FloatTensor - size: 1x1\n",
        "  _pred_idx : LongTensor - size: 1\n",
        "  _max : FloatTensor - size: 1\n",
        "  unionvalids : FloatTensor - size: 1\n",
        "  nclasses : 1\n",
        "  totalValid : 1\n",
        "  _prediction : FloatTensor - size: 1\n",
        "  averageValid : 1\n",
        "}\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "==> saving model to /home/zayik/Desktop/CS491/RNNMC_BAG/model.net\t\n"
       ]
      },
      {
       "ename": "[string \"for i = 1, 2 do...\"]:5: attempt to call global 'test' (a nil value)\nstack traceback:\n\t[string \"for i = 1, 2 do...\"]:5: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/zayik/torch/install/share/lua/5.1/itorch/main.lua:174: in function </home/zayik/torch/install/share/lua/5.1/itorch/main.lua:140>\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/zayik/torch/install/share/lua/5.1/itorch/main.lua:341: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406170",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "[string \"for i = 1, 2 do...\"]:5: attempt to call global 'test' (a nil value)\nstack traceback:\n\t[string \"for i = 1, 2 do...\"]:5: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/zayik/torch/install/share/lua/5.1/itorch/main.lua:174: in function </home/zayik/torch/install/share/lua/5.1/itorch/main.lua:140>\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/zayik/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/zayik/torch/install/share/lua/5.1/itorch/main.lua:341: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00406170"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(classes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "{\n",
        "  1 : 1\n",
        "  2 : 2\n",
        "  3 : 3\n",
        "  4 : 4\n",
        "}\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}